# -*- coding: utf-8 -*-
"""Image_generator_DCGAN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p9SXf11BC3HXvmS7tZat-uJxfMmXoP8P
"""

!pip install torch torchvision matplotlib numpy

from google.colab import files

# Upload kaggle.json
files.upload()

import os

# Make a directory named .kaggle
!mkdir -p ~/.kaggle

# Move kaggle.json to this directory
!cp kaggle.json ~/.kaggle/

# Change the permissions of the file
!chmod 600 ~/.kaggle/kaggle.json

# Download the dataset from Kaggle
!kaggle datasets download -d ikarus777/best-artworks-of-all-time

# Unzip the downloaded dataset
!unzip best-artworks-of-all-time.zip -d ./art_dataset

import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from torchvision.utils import make_grid
import matplotlib.pyplot as plt

# Define transformations for the images
transform = transforms.Compose([
    transforms.Resize(64),             # Resize images to 64x64
    transforms.CenterCrop(64),         # Center crop to 64x64
    transforms.ToTensor(),             # Convert images to tensors
    transforms.Normalize([0.5], [0.5], [0.5])  # Normalize to [-1, 1]
])

# Path to your extracted dataset
dataset_path = './art_dataset/images'  # Adjust this path if the images are inside another folder

# Load the dataset using ImageFolder
art_dataset = datasets.ImageFolder(root=dataset_path, transform=transform)

# Create a DataLoader for the dataset
dataloader = DataLoader(art_dataset, batch_size=128, shuffle=True, num_workers=2)

# Visualize some sample images
sample_batch = next(iter(dataloader))
sample_images = sample_batch[0]
grid_img = make_grid(sample_images[:16], nrow=4, normalize=True)
plt.imshow(grid_img.permute(1, 2, 0))
plt.axis('off')
plt.show()

import os
import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from torchvision.utils import make_grid, save_image
import matplotlib.pyplot as plt

import torch.nn as nn

class Generator(nn.Module):
    def __init__(self, latent_dim, ngf, nc):
        super(Generator, self).__init__()
        self.model = nn.Sequential(
            nn.ConvTranspose2d(latent_dim, ngf * 8, 4, 1, 0, bias=False),
            nn.BatchNorm2d(ngf * 8),
            nn.ReLU(True),
            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 4),
            nn.ReLU(True),
            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 2),
            nn.ReLU(True),
            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf),
            nn.ReLU(True),
            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),
            nn.Tanh()
        )

    def forward(self, x):
        return self.model(x)

class Discriminator(nn.Module):
    def __init__(self, nc, ndf):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 2),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 4),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 8),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.model(x).view(-1)

# Hyperparameters
latent_dim = 100
ngf = 64  # Generator feature map size
ndf = 64  # Discriminator feature map size
nc = 3    # Number of color channels

# Create the models
generator = Generator(latent_dim, ngf, nc).to('cuda')
discriminator = Discriminator(nc, ndf).to('cuda')

# Loss function and optimizers
criterion = nn.BCELoss()
optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))
optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))

num_epochs = 50  # Adjust based on your dataset and available resources
sample_interval = 500  # Interval for saving generated images

# Training loop
for epoch in range(num_epochs):
    for i, (real_images, _) in enumerate(dataloader):
        real_images = real_images.to('cuda')
        batch_size = real_images.size(0)

        # Train Discriminator
        real_labels = torch.ones(batch_size, device='cuda')
        fake_labels = torch.zeros(batch_size, device='cuda')

        optimizer_D.zero_grad()
        outputs = discriminator(real_images)
        d_loss_real = criterion(outputs, real_labels)
        d_loss_real.backward()

        noise = torch.randn(batch_size, latent_dim, 1, 1, device='cuda')
        fake_images = generator(noise)
        outputs = discriminator(fake_images.detach())
        d_loss_fake = criterion(outputs, fake_labels)
        d_loss_fake.backward()
        optimizer_D.step()

        # Train Generator
        optimizer_G.zero_grad()
        outputs = discriminator(fake_images)
        g_loss = criterion(outputs, real_labels)  # Generator tries to fool the discriminator
        g_loss.backward()
        optimizer_G.step()

        if i % sample_interval == 0:
            print(f'Epoch [{epoch}/{num_epochs}], Step [{i}/{len(dataloader)}], D Loss: {d_loss_real.item() + d_loss_fake.item()}, G Loss: {g_loss.item()}')
            with torch.no_grad():
                sample_noise = torch.randn(64, latent_dim, 1, 1, device='cuda')
                sample_images = generator(sample_noise)
                save_image((sample_images + 1) / 2, f'generated_samples/epoch_{epoch}_step_{i}.png')

os.makedirs('/content/generated_samples', exist_ok=True)

import matplotlib.pyplot as plt
from PIL import Image
import os

# Directory where the generated images are saved
image_dir = '/content/generated_samples'

# List the files in the directory
image_files = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.png')])

# Number of images to display
num_images = 5  # Change this to the number of images you want to display

# Display the images using matplotlib
plt.figure(figsize=(15, 5))
for i in range(num_images):
    # Open the image file
    img = Image.open(image_files[i])

    # Plot the image
    plt.subplot(1, num_images, i + 1)
    plt.imshow(img)
    plt.axis('off')  # Hide the axes

# Show the plot
plt.show()

